# noise test
model: GPT-3.5-turbo
dataset: base_math
start_num: 0
test_num: 500
run_time: 1
batch_size: 5

## COT 
if_COT: True
n_shots: 0
ex_shots: 0 # self-made excellent shots

## noise
if_noise: True
noisy_shots: 3
noisy_type: distracting # distracting, miscalculation, misunderstanding

## prefix
# prefix_context: True

# math base
base_math:
  base: 9
  

# GPT
GPT:
  api: openai  # openai or hkbu


# llama2 
llama2:
  ckpt_dir: /vol/home/lanlong/xuanli/code/llama-main/llama-2-7b-chat/
  tokenizer_path: /vol/home/lanlong/xuanli/code/llama-main/tokenizer.model
  max_seq_len: 4000
  max_batch_size: 10
