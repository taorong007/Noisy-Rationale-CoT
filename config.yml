# noise test
model: GPT-3.5-turbo
dataset: base_math
start_num: 0
test_num: 100
run_time: 1
batch_size: 1

## COT 
if_COT: True
n_shots: 2
ex_shots: 2 # self-made excellent shots

## noise
if_noise: False
error_shots: 0
error_type: miscalculation

## prefix
# prefix_context: True

# math base
base_math:
  base: 9
  

# GPT
GPT:
  api: openai  # openai or hkbu


# llama2 
llama2:
  ckpt_dir: /vol/home/lanlong/xuanli/code/llama-main/llama-2-7b-chat/
  tokenizer_path: /vol/home/lanlong/xuanli/code/llama-main/tokenizer.model
  max_seq_len: 4000
  max_batch_size: 10
