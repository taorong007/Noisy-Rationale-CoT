# noise test
model: llama2
dataset: GSM # family_relation and base_math and GSM
start_num: 0
test_num: 200
run_times: 1
batch_size: 5

## in-context 
if_in_context: True
n_shots: 3 # self-made excellent shots
# n_weak_shots: 0 # original author's shots 

## noise
if_noise: False
n_noisy_shots: 3
noisy_type: arithmetic_error # base math: irrelative or arithmetic_error
noisy_level: 3
## prefix
prefix_context: True

# math base
base_math:
  base: 9
  

# gpt
gpt:
  api: openai  # openai or hkbu
  temperature: 0

family_relation:
  train_set: 3

# llama2 
llama2:
  ckpt_dir: /vol/home/lanlong/xuanli/code/llama-main/llama-2-7b-chat/
  tokenizer_path: /vol/home/lanlong/xuanli/code/llama-main/tokenizer.model
  max_seq_len: 4000
  max_batch_size: 10
